---
title: "02_data-analysis"
output:
  github_document:
    toc: true
    toc_depth: 2
---
# appeler la librairie dada2
```{r message=FALSE}
library("dada2")
```

Définir la variable path suivante pour qu'elle pointe vers le répertoire Miseq_sop extrait sur la machine.
Les données utilisées sont dans le fichier donnees que j'ai crée et j'ai mis tous les données importées dedans. Pour l'instant, considérez simplement les fichiers fastq appariés à traiter.
```{r, results='hide'}
path <- "~/github/ecog2_cc2/donnees" # CHANGE ME to the directory containing the fastq files after unzipping.
list.files(path)
```
```{r}
# Forward and reverse fastq filenames have format: SAMPLENAME_R1.fastq and SAMPLENAME_R2_001.fastq
fnFs <- sort(list.files(path, pattern="_R1.fastq", full.names = TRUE))
fnRs <- sort(list.files(path, pattern="_R2.fastq", full.names = TRUE))
# Extract sample names, assuming filenames have format: SAMPLENAME_XXX.fastq
sample.names <- sapply(strsplit(basename(fnFs), "R"), `[`, 1)
```

# Inspect read quality profiles
Nous commençons par visualiser les profils de qualité des Forward reads en utilisant la fonction plotQualityProfile qui va permettre de tracer un résumé visuel de la distribution des scores de qualité en fonction de la position de la séquence pour le fichier: fnFs fastq d'entrée.

```{r}
library(dada2)
plotQualityProfile(fnFs[1:2])
```
```{r}
plotQualityProfile(fnRs[1:2])
```
# Filter and trim

```{r}
# Place filtered files in filtered/ subdirectory
filtFs <- file.path(path, "filtered", paste0(sample.names, "_F_filt.fastq.gz"))
filtRs <- file.path(path, "filtered", paste0(sample.names, "_R_filt.fastq.gz"))
names(filtFs) <- sample.names
names(filtRs) <- sample.names
```

Nous utiliserons les paramètres de filtrage standard: maxN=0(DADA2 ne nécessite aucun Ns) truncQ=2, rm.phix=TRUEet maxEE=2. Le aramètre maxEEp définit le nombre maximum d '«erreurs attendues» autorisées dans une lecture.
Ici, on crée une variale out et on lui assigne les valeurs des résultats de la fonction filterAndTrim(), qui va filtrer et ajuster les fichiers fnFs, filtFs, fnRs, filtRs de  fastq d'entrée (peut être compressé) en fonction de plusieurs critères:  maxN=0, maxEE=c(2,2), truncQ=2, rm.phix=TRUE,
compress=TRUE, multithread=TRUE , et génère des fichiers fastq (compressés par défaut) contenant les lectures coupées qui ont passé les filtres. Des fichiers fastq revers et forward correspondants peuvent être fournis en entrée, auquel cas le filtrage est effectué sur les lectures avant et arrière indépendamment, et les deux lectures doivent passer pour que la paire de lecture soit sortie.
En suite on va utiliser la fonction head pour avoir un apperçu de l'objet out

```{r}
out <- filterAndTrim(fnFs, filtFs, fnRs, filtRs, truncLen=c(240,200),trimLeft=c(21),
              maxN=0, maxEE=c(2,2), truncQ=2, rm.phix=TRUE,
              compress=TRUE, multithread=TRUE) # On Windows set multithread=FALSE
head(out)
```
# appretissage des erreurs

dada2 calcul un model d'erreurs apartir des données de séquençage, cette méthode sur les reads F Reverse. 
L'algorithme DADA2 utilise un modèle d'erreur paramétrique ( err) et chaque jeu de données d'amplicon a un ensemble différent de taux d'erreur. La learnErrors méthode apprend ce modèle d'erreur à partir des données, en alternant l'estimation des taux d'erreur et l'inférence de la composition de l'échantillon jusqu'à ce qu'ils convergent vers une solution cohérente conjointement. 

```{r}
errF <- learnErrors(filtFs, multithread=TRUE)
```
dada2 calcul un model d'erreurs apartir des données de séquençage, cette méthode sur les reads Reverse de la même manière que pour errF

```{r}
errR <- learnErrors(filtRs, multithread=TRUE)
```

le code suivant est pour vérifier si rien d'autre, de visualiser les taux d'erreur estimés en utilisant la fonction plotErrors. Cette fonction va tracer la fréquence observée de chaque transition (par exemple A-> C) en fonction du score de qualité associé. Il trace également les taux d'erreur estimés finaux (s'ils existent). l'argument nominalQ=TRUE va permettre de tracer les taux d'erreur attendus (ligne rouge) si les scores de qualité correspondent exactement à leur définition nominale: Q = -10 log10 (p_err).

```{r message=FALSE}
plotErrors(errF, nominalQ=TRUE)
```
Intérprétation de graphe précédent: graphe 1: la probabilité que A est A doit être max ainsi de suite...
les taux d'erreur pour chaque transition sont indiquées sur les graphes (graphe 2: A-->C etc)
c2: probabilité d'erreus de séq pour qu'un A soit un C.
 Ici, les taux d'erreur estimés (ligne noire) correspondent bien aux taux observés (points), et les taux d'erreur diminuent avec une qualité accrue comme prévu. Tout semble raisonnable et nous procédons en toute confiance.

# sample inference
on crée une nouvelle variable dadaFs pour corriger les jeux de données
dada appliquée au donné Forward.
La fonction dada supprime toutes les erreurs de séquençage pour révéler les membres de la communauté séquencée. l'argument multithread=TRUE: le multithreading est activé et le nombre de threads disponibles est automatiquement déterminé. Si un entier est fourni, le nombre de threads à utiliser est défini en transmettant l'argument à setThreadOptions.

```{r}
dadaFs <- dada(filtFs, err=errF, multithread=TRUE)
```
dada appliqué au donné reverse
on crée une nouvelle variable dadaRs et on lui assigne la valeur de résultat de la fonction dada comme on a fait pour les reverse à fin de corriger les jeux de données appliquées pour les Reverse.

```{r}
dadaRs <- dada(filtRs, err=errR, multithread=TRUE)
```

dada a crée des objet de class dada: dadaFs et dada Rs
on regarde ce qui est dans le premier étagers du placard de dadaFS, on peut changer le 1 pour regarder à n'importe quel étage de dadaFS.

```{r}
dadaFs[[1]]
```

# mairged paired reads

on va merger Read 1 et read 2 pour obtenir les séquences entièrement débruitées en utilisant la fonction mergePairs(). La fusion est effectuée en alignant les lectures avant débruitées avec le complément inverse des lectures inverses débruitées correspondantes, puis en construisant les séquences «contig» fusionnées.
verbose=TRUE:monter les étape avec le texte
head(mergers[[1]]):inspecter les résultats en regardant les premières lignes

```{r}
mergers <- mergePairs(dadaFs, filtFs, dadaRs, filtRs, verbose=TRUE)
# Inspect the merger data.frame from the first sample
head(mergers[[1]])
```

Donc là on a les reads fusionnés avec succès.

# construire la table d'observation

à partir des merged, on crée un nouvelle objet seqtab 
la fonction va permettre de construire une table de séquence (analogue à une table OTU) à partir de la liste d'échantillon mergers.
la fonction dim va permettre de récupérer l'objet seqtab.
 
```{r}
seqtab <- makeSequenceTable(mergers)
dim(seqtab)
```
regarder la distribution de la longeur des séquences.
La table de séquence est une matrix avec des lignes correspondant aux (et nommées par) les échantillons, et des colonnes correspondant (et nommées par) les variantes de séquence. 

```{r}
# Inspect distribution of sequence lengths
table(nchar(getSequences(seqtab)))
```
dans mon objet seqtab j'ai une séq qui fait 251 paires de bases, une autre qui fait 252 etc

# Remove chimeras

une chimère: ça se passe pendant l'amplification par PCR
donc par ex un ADN 16s amplifier par un fragment reverse et forrward.
Si on prend que le forward,y aura élongation mais imaginant qu'elle s'arréte avant la fin de la séq 16S.
Donc on va avoir le fragment 16S qui n'a pas bouger et un fragment non complet. donc àprès le 2ème cycle, le fragment non complet va pouvoir s'hybrider avec un 16s d'une autre bactérie, et l'élongation va continuer.
on va avoir comme résultat au final un fragment hybride qui provient du premier ARN 16 et du deuxième.
cela s'appelle chimère.
On va éliminer ces chimères en utlisant la fonction removeBimeraDenovo
le système va regarder tout les séq rares dans le début contig correspont au premier ARN et la fin au deuxième.

```{r message=FALSE}
seqtab.nochim <- removeBimeraDenovo(seqtab, method="consensus", multithread=TRUE, verbose=TRUE)
dim(seqtab.nochim)
```
Donc le résultat montre qui il a détectrer 61 (=293-232) chimère sur 293(= 1+88+196+6+2).

calcul de ratio chimère qui est égale à la somme des sequences se trouvant dans l'objet seqtab.mochim (c'est l'objet après remove des chimères) / somme des séquences se traouvent dans l'objet seqtab(avant d'enlever les chimères)

```{r}
sum(seqtab.nochim)/sum(seqtab)
```

y a (1-0.96)*100 = 3.5% de séq chimériques dans notre jeu de données.
les chimères représentent environ 21% des variantes de séquence fusionnées, mais lorsque nous tenons compte de l'abondance de ces variantes, nous voyons qu'elles ne représentent qu'environ 4% des lectures de séquence fusionnée.

# Track reads through the pipeline

résumé des fichiers qualité.
construire une table 
on crée un nouvel objet qui est getN c'est une variable qui prend le rôle d'une fonction
apliquer la fonnction get N qui est la somme des get uniq de dadaFS
la table track va être la concaténation de tout ce qui est entre parentèse.
head(track) : pour visualiser le tableau

```{r}
getN <- function(x) sum(getUniques(x))
track <- cbind(out, sapply(dadaFs, getN), sapply(dadaRs, getN), sapply(mergers, getN), rowSums(seqtab.nochim))
# If processing a single sample, remove the sapply calls: e.g. replace sapply(dadaFs, getN) with getN(dadaFs)
colnames(track) <- c("input", "filtered", "denoisedF", "denoisedR", "merged", "nonchim")
rownames(track) <- sample.names
head(track)
```

On a conservé la majorité des lectures brutes et aucune baisse trop importante n'est associée à une seule étape.

# assignation de la taxonomie

il va regarder dans le base de données et à partir des séq qui sont proches, et va assigner une taxonomie.

c'est une façon d'attribuer une taxonomie aux séquences.
La fonction assignTaxonomy prend en entrée un ensemble de séquences à classer et un ensemble d'apprentissage de séquences de référence avec une taxonomie connue (silva en ce cas), et produit des affectations taxonomiques avec au moins une minBootconfiance bootstrap.


```{r}
taxa <- assignTaxonomy(seqtab.nochim, "~/silva_nr99_v138_train_set.fa.gz", multithread=TRUE)
```

ajout d'espèces, téléchargement du fichier et le placer dans le répertoire taxa contenant les fichiers fastq.

```{r}
taxa <- addSpecies(taxa, "~/silva_species_assignment_v138.fa.gz")
```

Inspecter les affectations taxonomiques:

```{r}
taxa.print <- taxa # Removing sequence rownames for display only
rownames(taxa.print) <- NULL
head(taxa.print)
```

les Bacteroidetes sont bien représentés parmi les taxons les plus abondants dans ces échantillons fécaux. Peu d'attributions d'espèces ont été faites, à la fois parce qu'il est souvent impossible de faire des assignations d'espèces sans ambiguïté à partir de sous-segments du gène 16S, et parce qu'il y a étonnamment peu de couverture du microbiote intestinal de souris indigène dans les bases de données de référence.


```{r}
save.image(file="02_data-analysis")
```
